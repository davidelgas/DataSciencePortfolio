{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "64B8Z8Zc6_qL",
        "t8tsltRK6_sc",
        "iiUUMoqW6_u-",
        "jC3997sK6_xo",
        "8tHREmv66_0j",
        "slEeYQzK6_3L",
        "Z82Fb6r_6_55"
      ],
      "authorship_tag": "ABX9TyNQGPgOGHpd+aSQwVTF5lIP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidelgas/DataSciencePortfolio/blob/main/Knowledge%20Graph/Knowledge_Graph_with_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview"
      ],
      "metadata": {
        "id": "B74IjdlZP8q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook I will be creating a small NN and a knowledge graph with an open source e-Commerce dataset.\n",
        "\n",
        "\n",
        "My use case:<br>\n",
        "A language interface (chatbot or search engine) that answers user queries.<br>\n",
        "A knowledge graph to structure relationships between products, conversations, and recommendations.<br>\n",
        "A PyTorch-based neural network for embeddings, retrieval, or ranking.<br>\n",
        "Retrieval-Augmented Generation (RAG) to enhance responses with knowledge graph lookups.<br><br>\n",
        "\n"
      ],
      "metadata": {
        "id": "m_PtksQiY6Vq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "**Product Metadata**<br>\n",
        "Describes the structured attributes of a product, such as name, brand, category, price, specifications, and descriptions. This data is essential for building a knowledge graph and improving search and recommendation systems.\n",
        "\n",
        "**User Interactions**<br>\n",
        "Refers to data on how users engage with products, including clicks, purchases, reviews, ratings, wish lists, and cart additions. This data is valuable for recommendation systems and behavior-based predictions.\n",
        "\n",
        "**Graph-Friendly**<br>\n",
        "Indicates whether the dataset has a structure that can be easily converted into a knowledge graph. This means it contains relationships between entities, such as product-category, user-bought-product, or brand-produces-product.\n",
        "\n",
        "**Pre-Built KG**<br>\n",
        "A dataset that already includes a knowledge graph structure with entities (products, categories, users) and relationships. This saves time in preprocessing and can be directly used for graph neural networks (GNNs) and embeddings.\n",
        "\n",
        "**Good for PyTorch NN**<br>\n",
        "Determines whether the dataset is well-suited for training a neural network in PyTorch, particularly for tasks like embedding generation, recommendation systems, or graph-based learning. This usually depends on the datasetâ€™s structure, size, and data richness.\n",
        "\n",
        "\n",
        "## Dataset Scoring (1-5 Scale)\n",
        "\n",
        "| Dataset                     | Product Metadata | User Interactions | Graph-Friendly | Pre-Built KG | Good for PyTorch NN | Total Score |\n",
        "|-----------------------------|-----------------|-------------------|---------------|-------------|---------------------|-------------|\n",
        "| **ICECAT**                  | 5               | 1                 | 4             | 1           | 4                   | **15**      |\n",
        "| **Olist**                   | 4               | 5                 | 4             | 1           | 5                   | **19**      |\n",
        "| **AliExpress KG**           | 5               | 5                 | 5             | 5           | 5                   | **25**      |\n",
        "| **Facebook AI eCommerce KG**| 5               | 5                 | 5             | 5           | 5                   | **25**      |\n",
        "| **DBPedia + Wikidata**      | 5               | 1                 | 5             | 5           | 2                   | **18**      |\n"
      ],
      "metadata": {
        "id": "kXRMjWd3bJiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workfow\n",
        "\n",
        "1.   Load dataset\n",
        "2.   Preprocess and Clean the Data\n",
        "3.   Convert Data into a Knowledge Graph Structure\n",
        "4.   Generate Knowledge Graph Embeddings\n",
        "5.   Build a Graph-Based Recommendation Model\n",
        "6.   Integrate Conversational AI (Natural Language Model)\n",
        "7.   Train & Optimize the Full System\n",
        "8.   Implement Real-Time Inference for Recommendations\n",
        "9.   Deploy as an Interactive API or Chatbot\n",
        "10.  Apppendx of code and notes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TZGx4I6FHCHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access to Google Drive\n",
        "# This seems to propagate credentials better from its own cell\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MO2kbk7afp3",
        "outputId": "709002f6-2dd2-4539-e96c-fda6f3bbdf2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "OljZpwOhukMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "6-j3Ic92UlqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Data into a Knowledge Graph Structure"
      ],
      "metadata": {
        "id": "64B8Z8Zc6_qL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Knowledge Graph Embeddings"
      ],
      "metadata": {
        "id": "t8tsltRK6_sc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Graph-Based Recommendation Model"
      ],
      "metadata": {
        "id": "iiUUMoqW6_u-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrate Conversational AI (Natural Language Model)"
      ],
      "metadata": {
        "id": "jC3997sK6_xo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train & Optimize the Full System"
      ],
      "metadata": {
        "id": "8tHREmv66_0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement Real-Time Inference for Recommendations"
      ],
      "metadata": {
        "id": "slEeYQzK6_3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy as an Interactive API or Chatbot"
      ],
      "metadata": {
        "id": "Z82Fb6r_6_55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix"
      ],
      "metadata": {
        "id": "GRLnTAAAuxUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scoring Criteria for Selecting an Encoder\n",
        "\n",
        "\n",
        "| **Factor**                 | **Description** |\n",
        "|---------------------------|----------------|\n",
        "| **Computational Efficiency** | How fast is the encoding on CPU/GPU? |\n",
        "| **Memory Usage**          | How much memory does it require? |\n",
        "| **Scalability**           | Can it handle large datasets like OpenBG500? |\n",
        "| **Preserves Semantic Meaning** | Does the encoding capture relationships between entities? |\n",
        "| **Compatibility with PyTorch** | How well does it integrate into PyTorch models? |\n",
        "| **Ease of Implementation** | How difficult is it to set up? |\n",
        "\n",
        "Each encoding method gets a **score from 1 to 5** for each factor.\n",
        "\n",
        "---\n",
        "\n",
        "## Scoring Different Encoding Methods\n",
        "\n",
        "| Encoding Method  | Computational Efficiency | Memory Usage | Scalability | Semantic Meaning | PyTorch Compatibility | Ease of Implementation | **Total Score** |\n",
        "|-----------------|------------------------|--------------|-------------|------------------|----------------------|--------------------|--------------|\n",
        "| **Label Encoding** (Integer Mapping) | **5** (Very fast) | **5** (Very low) | **5** (Handles millions of nodes) | **1** (No meaning captured) | **5** (PyTorch works with integers easily) | **5** (Simple `map()`) | **26** |\n",
        "| **One-Hot Encoding** | **2** (Slow for large datasets) | **1** (Consumes huge memory) | **1** (Bad for large graphs) | **3** (Some structure captured) | **3** (Can be used, but not ideal) | **3** (Easy but inefficient) | **13** |\n",
        "| **BERT Embeddings** (Text-Based) | **2** (Slow on CPU) | **3** (Moderate) | **3** (Can use pre-trained models) | **5** (Captures meaning well) | **4** (PyTorch supports it, but needs preprocessing) | **2** (Requires NLP model) | **19** |\n",
        "| **Word2Vec/FastText** | **3** (Faster than BERT) | **3** (Moderate) | **4** (Good for large datasets) | **4** (Captures word meaning) | **4** (PyTorch supports it) | **3** (Requires preprocessing) | **21** |\n",
        "| **Knowledge Graph Embeddings (TransE, RotatE)** | **4** (Moderate) | **4** (Efficient for large graphs) | **5** (Scales well) | **5** (Captures graph meaning) | **5** (Designed for PyTorch models) | **3** (Requires model training) | **26** |\n",
        "\n"
      ],
      "metadata": {
        "id": "w1WMfj7DuMfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all unique entities (from both head and tail)\n",
        "all_entities = set(triples_df_train[\"head\"]).union(set(triples_df_train[\"tail\"]))\n",
        "\n",
        "# Get all unique relations\n",
        "all_relations = set(triples_df_train[\"relation\"])\n",
        "\n",
        "# Create mapping dictionaries\n",
        "entity2id = {entity: idx for idx, entity in enumerate(all_entities)}\n",
        "relation2id = {relation: idx for idx, relation in enumerate(all_relations)}\n",
        "\n",
        "def encode_triples(df):\n",
        "    df[\"head\"] = df[\"head\"].map(entity2id)\n",
        "    df[\"relation\"] = df[\"relation\"].map(relation2id)\n",
        "    df[\"tail\"] = df[\"tail\"].map(entity2id)\n",
        "    return df\n",
        "\n",
        "# Encode train, test, and validation sets\n",
        "triples_df_train = encode_triples(triples_df_train)\n",
        "triples_df_test = encode_triples(triples_df_test)\n",
        "triples_df_val = encode_triples(triples_df_val)\n"
      ],
      "metadata": {
        "id": "pHs0Bg06wJEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Convert to tensor format\n",
        "train_tensor = torch.tensor(triples_df_train.values, dtype=torch.long)\n",
        "test_tensor = torch.tensor(triples_df_test.values, dtype=torch.long)\n",
        "val_tensor = torch.tensor(triples_df_val.values, dtype=torch.long)"
      ],
      "metadata": {
        "id": "0OT9yU2Kwh7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check the shape of the tensors\n",
        "print(\"Train Tensor Shape:\", train_tensor.shape)\n",
        "print(\"Test Tensor Shape:\", test_tensor.shape)\n",
        "print(\"Validation Tensor Shape:\", val_tensor.shape)\n",
        "\n",
        "# Access the first 5 samples\n",
        "print(\"First 5 Training Samples:\\n\", train_tensor[:5])\n",
        "\n",
        "# Get specific columns\n",
        "heads = train_tensor[:, 0]  # Head entities\n",
        "relations = train_tensor[:, 1]  # Relations\n",
        "tails = train_tensor[:, 2]  # Tail entities\n",
        "\n",
        "print(\"First 5 Head Entities:\\n\", heads[:5])\n",
        "print(\"First 5 Relations:\\n\", relations[:5])\n",
        "print(\"First 5 Tail Entities:\\n\", tails[:5])\n",
        "\n",
        "# Perform simple operations\n",
        "sum_tensor = heads + tails  # Example tensor addition\n",
        "print(\"Sum of Head & Tail Entities:\\n\", sum_tensor[:5])\n",
        "\n",
        "# Get unique values\n",
        "unique_heads = torch.unique(heads)\n",
        "print(f\"Unique Head Entities Count: {unique_heads.shape[0]}\")\n"
      ],
      "metadata": {
        "id": "Z4eelogAxJIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cpu\")  # Force CPU mode for now\n",
        "\n",
        "print(\"Using Device:\", device)\n"
      ],
      "metadata": {
        "id": "t5kgl1K566zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple MLP model\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "# Three layer network\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Set dimensions\n",
        "input_dim = 3  # (head, relation, tail)\n",
        "hidden_dim = 16\n",
        "output_dim = 1  # Binary classification or regression\n",
        "\n",
        "# Initialize model\n",
        "model = SimpleMLP(input_dim, hidden_dim, output_dim).to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()  # Example: MSE loss for regression\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Dummy training loop\n",
        "for epoch in range(5):  # Short training example\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(train_tensor.float())  # Convert tensor to float for Linear layers\n",
        "    loss = criterion(outputs, torch.rand_like(outputs))  # Dummy target values\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "id": "cDdRgsUR6tST"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}