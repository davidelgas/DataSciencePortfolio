{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3RZ5oGvjay0SsoTc+VNDS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidelgas/DataSciencePortfolio/blob/main/Neural%20Network%20with%20Knowledge%20Graph/KG_DNN_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview"
      ],
      "metadata": {
        "id": "B74IjdlZP8q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook I will be creating a small NN and a knowledge graph with an open source e-Commerce dataset.\n",
        "\n",
        "\n",
        "My use case:<br>\n",
        "A language interface (chatbot or search engine) that answers user queries.<br>\n",
        "A knowledge graph to structure relationships between products, conversations, and recommendations.<br>\n",
        "A PyTorch-based neural network for embeddings, retrieval, or ranking.<br>\n",
        "Retrieval-Augmented Generation (RAG) to enhance responses with knowledge graph lookups.<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "m_PtksQiY6Vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access to Google Drive\n",
        "# This seems to propagate credentials better from its own cell\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MO2kbk7afp3",
        "outputId": "b8cd05eb-5c4b-4ab0-8366-97b99620f0f7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workfow\n",
        "\n",
        "\n",
        "1.   Load dataset\n",
        "2.   Preprocess and Clean the Data\n",
        "3.   Convert Data into a Knowledge Graph Structure\n",
        "4.   Generate Knowledge Graph Embeddings\n",
        "5.   Build a Graph-Based Recommendation Model\n",
        "6.   Integrate Conversational AI (Natural Language Model)\n",
        "7.   Train & Optimize the Full System\n",
        "8.   Implement Real-Time Inference for Recommendations\n",
        "9.   Deploy as an Interactive API or Chatbot\n",
        "10.  Apppendx of code and notes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TZGx4I6FHCHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "OljZpwOhukMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# I tried the Grocerie dataset, but dial_gt_context_train is corrupt.\n",
        "\n",
        "dial_gt_context_test = np.load(\"/content/dial_gt_context_test.npz\", allow_pickle=True)\n",
        "\n",
        "dial_gt_context_train = np.load(\"/content/dial_gt_context_train.npz\", allow_pickle=True)\n",
        "\n",
        "dial_gt_context_val = np.load(\"/content/dial_gt_context_val.npz\", allow_pickle=True)\n",
        "\n",
        "dial_utter_resp_test = np.load(\"/content/dial_utter_resp_test.npz\", allow_pickle=True)\n",
        "\n",
        "dial_utter_resp_train = np.load(\"/content/dial_utter_resp_train.npz\", allow_pickle=True)\n",
        "\n",
        "dial_utter_resp_val = np.load(\"/content/dial_utter_resp_val.npz\", allow_pickle=True)\n",
        "\n",
        "dial_word_embed = np.load(\"/content/dial_word_embed.npz\", allow_pickle=True)\n",
        "\n",
        "rec_test_candidate100 = np.load(\"/content/rec_test_candidate100.npz\", allow_pickle=True)\n",
        "\n",
        "rec_val_candidate100 = np.load(\"/content/rec_val_candidate100.npz\", allow_pickle=True)\n",
        "\n",
        "\n",
        "# /content/vocab_and_embeddings.pkl"
      ],
      "metadata": {
        "id": "3a1AJuaaaaep"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = {\n",
        "    \"dial_gt_context_test\": dial_gt_context_test,\n",
        "    \"dial_gt_context_train\": dial_gt_context_train,\n",
        "    \"dial_gt_context_val\": dial_gt_context_val,\n",
        "    \"dial_utter_resp_test\": dial_utter_resp_test,\n",
        "    \"dial_utter_resp_train\": dial_utter_resp_train,\n",
        "    \"dial_utter_resp_val\": dial_utter_resp_val,\n",
        "    \"dial_word_embed\": dial_word_embed,\n",
        "    \"rec_test_candidate100\": rec_test_candidate100,\n",
        "    \"rec_val_candidate100\": rec_val_candidate100\n",
        "}\n",
        "\n",
        "\n",
        "def look_at_files(files):\n",
        "    for name, data in files.items():  # Loop through dictionary items\n",
        "        print(f\"\\nInspecting {name}\")\n",
        "        print(f\"Stored arrays: {data.files}\")  # List arrays in each NPZ file\n",
        "\n",
        "        for key in data.files:\n",
        "            array = data[key]\n",
        "            print(f\"Array Name: {key}\")\n",
        "            print(f\"   Type: {type(array)}\")\n",
        "            print(f\"   Shape: {array.shape}\")\n",
        "            print(f\"   Data Type: {array.dtype}\")\n",
        "\n",
        "            # Check if the array contains structured data\n",
        "            if array.dtype.names:  # This checks for structured NumPy arrays with named columns\n",
        "                print(f\"   Columns: {array.dtype.names}\")\n",
        "\n",
        "            # Print a sample of the data\n",
        "            #print(f\"   Sample Data: {array[:2]}\")  # Print first 2 samples\n",
        "            print(\"-\" * 50)  # Separator for readability\n",
        "\n",
        "# Run the function on your loaded files\n",
        "look_at_files(files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRIpbz1rMAnV",
        "outputId": "294946cb-c1ad-484c-e8a8-f52eff80ea00"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inspecting dial_gt_context_test\n",
            "Stored arrays: ['utter_gt', 'utter_context', 'resp_gt', 'resp_contexst', 'dial_length']\n",
            "Array Name: utter_gt\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (127712, 10, 1)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: utter_context\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (127712, 10, 24)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: resp_gt\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (1277120, 1)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: resp_contexst\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (1277120, 24)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: dial_length\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (127712,)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "\n",
            "Inspecting dial_gt_context_train\n",
            "Stored arrays: ['utter_gt', 'utter_context', 'resp_gt', 'resp_context']\n",
            "Array Name: utter_gt\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (361590, 10, 1)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: utter_context\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (361590, 10, 24)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: resp_gt\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (723180, 1)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: resp_context\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (723180, 24)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "\n",
            "Inspecting dial_gt_context_val\n",
            "Stored arrays: ['utter_gt', 'utter_context', 'resp_gt', 'resp_context']\n",
            "Array Name: utter_gt\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (119421, 10, 1)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: utter_context\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (119421, 10, 24)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: resp_gt\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (1194210, 1)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: resp_context\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (1194210, 24)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "\n",
            "Inspecting dial_utter_resp_test\n",
            "Stored arrays: ['utterance', 'response', 'label']\n",
            "Array Name: utterance\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (127712, 10, 50)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: response\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (1277120, 50)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: label\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (1277120,)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "\n",
            "Inspecting dial_utter_resp_train\n",
            "Stored arrays: ['utterance', 'response', 'label']\n",
            "Array Name: utterance\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (361590, 10, 50)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: response\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (723180, 50)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: label\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (723180,)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "\n",
            "Inspecting dial_utter_resp_val\n",
            "Stored arrays: ['utterance', 'response', 'label']\n",
            "Array Name: utterance\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (119421, 10, 50)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: response\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (1194210, 50)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "Array Name: label\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (1194210,)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "\n",
            "Inspecting dial_word_embed\n",
            "Stored arrays: ['word_emb']\n",
            "Array Name: word_emb\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (19071, 200)\n",
            "   Data Type: float64\n",
            "--------------------------------------------------\n",
            "\n",
            "Inspecting rec_test_candidate100\n",
            "Stored arrays: ['candidates']\n",
            "Array Name: candidates\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (127712, 102)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n",
            "\n",
            "Inspecting rec_val_candidate100\n",
            "Stored arrays: ['candidates']\n",
            "Array Name: candidates\n",
            "   Type: <class 'numpy.ndarray'>\n",
            "   Shape: (119421, 102)\n",
            "   Data Type: int64\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess and Clean the Data"
      ],
      "metadata": {
        "id": "nRoQyVWn6_nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expose the arrays from each NPZ\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "extracted_arrays = {}\n",
        "\n",
        "# Iterate through each NPZ file and extract its arrays\n",
        "for file_name, npz_obj in files.items():\n",
        "    extracted_arrays[file_name] = {}\n",
        "    for array_name in npz_obj.files:\n",
        "        extracted_arrays[file_name][array_name] = npz_obj[array_name]\n",
        "        print(f\"Extracted {array_name} from {file_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXWRzve5QvNw",
        "outputId": "c5deff5e-205c-4552-a27a-81e573c489fc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted utter_gt from dial_gt_context_test\n",
            "Extracted utter_context from dial_gt_context_test\n",
            "Extracted resp_gt from dial_gt_context_test\n",
            "Extracted resp_contexst from dial_gt_context_test\n",
            "Extracted dial_length from dial_gt_context_test\n",
            "Extracted utter_gt from dial_gt_context_train\n",
            "Extracted utter_context from dial_gt_context_train\n",
            "Extracted resp_gt from dial_gt_context_train\n",
            "Extracted resp_context from dial_gt_context_train\n",
            "Extracted utter_gt from dial_gt_context_val\n",
            "Extracted utter_context from dial_gt_context_val\n",
            "Extracted resp_gt from dial_gt_context_val\n",
            "Extracted resp_context from dial_gt_context_val\n",
            "Extracted utterance from dial_utter_resp_test\n",
            "Extracted response from dial_utter_resp_test\n",
            "Extracted label from dial_utter_resp_test\n",
            "Extracted utterance from dial_utter_resp_train\n",
            "Extracted response from dial_utter_resp_train\n",
            "Extracted label from dial_utter_resp_train\n",
            "Extracted utterance from dial_utter_resp_val\n",
            "Extracted response from dial_utter_resp_val\n",
            "Extracted label from dial_utter_resp_val\n",
            "Extracted word_emb from dial_word_embed\n",
            "Extracted candidates from rec_test_candidate100\n",
            "Extracted candidates from rec_val_candidate100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Data into a Knowledge Graph Structure"
      ],
      "metadata": {
        "id": "64B8Z8Zc6_qL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Knowledge Graph Embeddings"
      ],
      "metadata": {
        "id": "t8tsltRK6_sc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Graph-Based Recommendation Model"
      ],
      "metadata": {
        "id": "iiUUMoqW6_u-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrate Conversational AI (Natural Language Model)"
      ],
      "metadata": {
        "id": "jC3997sK6_xo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train & Optimize the Full System"
      ],
      "metadata": {
        "id": "8tHREmv66_0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement Real-Time Inference for Recommendations"
      ],
      "metadata": {
        "id": "slEeYQzK6_3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy as an Interactive API or Chatbot"
      ],
      "metadata": {
        "id": "Z82Fb6r_6_55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix"
      ],
      "metadata": {
        "id": "GRLnTAAAuxUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scoring Criteria for Selecting an Encoder\n",
        "\n",
        "\n",
        "| **Factor**                 | **Description** |\n",
        "|---------------------------|----------------|\n",
        "| **Computational Efficiency** | How fast is the encoding on CPU/GPU? |\n",
        "| **Memory Usage**          | How much memory does it require? |\n",
        "| **Scalability**           | Can it handle large datasets like OpenBG500? |\n",
        "| **Preserves Semantic Meaning** | Does the encoding capture relationships between entities? |\n",
        "| **Compatibility with PyTorch** | How well does it integrate into PyTorch models? |\n",
        "| **Ease of Implementation** | How difficult is it to set up? |\n",
        "\n",
        "Each encoding method gets a **score from 1 to 5** for each factor.\n",
        "\n",
        "---\n",
        "\n",
        "## Scoring Different Encoding Methods\n",
        "\n",
        "| Encoding Method  | Computational Efficiency | Memory Usage | Scalability | Semantic Meaning | PyTorch Compatibility | Ease of Implementation | **Total Score** |\n",
        "|-----------------|------------------------|--------------|-------------|------------------|----------------------|--------------------|--------------|\n",
        "| **Label Encoding** (Integer Mapping) | **5** (Very fast) | **5** (Very low) | **5** (Handles millions of nodes) | **1** (No meaning captured) | **5** (PyTorch works with integers easily) | **5** (Simple `map()`) | **26** |\n",
        "| **One-Hot Encoding** | **2** (Slow for large datasets) | **1** (Consumes huge memory) | **1** (Bad for large graphs) | **3** (Some structure captured) | **3** (Can be used, but not ideal) | **3** (Easy but inefficient) | **13** |\n",
        "| **BERT Embeddings** (Text-Based) | **2** (Slow on CPU) | **3** (Moderate) | **3** (Can use pre-trained models) | **5** (Captures meaning well) | **4** (PyTorch supports it, but needs preprocessing) | **2** (Requires NLP model) | **19** |\n",
        "| **Word2Vec/FastText** | **3** (Faster than BERT) | **3** (Moderate) | **4** (Good for large datasets) | **4** (Captures word meaning) | **4** (PyTorch supports it) | **3** (Requires preprocessing) | **21** |\n",
        "| **Knowledge Graph Embeddings (TransE, RotatE)** | **4** (Moderate) | **4** (Efficient for large graphs) | **5** (Scales well) | **5** (Captures graph meaning) | **5** (Designed for PyTorch models) | **3** (Requires model training) | **26** |\n",
        "\n"
      ],
      "metadata": {
        "id": "w1WMfj7DuMfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all unique entities (from both head and tail)\n",
        "all_entities = set(triples_df_train[\"head\"]).union(set(triples_df_train[\"tail\"]))\n",
        "\n",
        "# Get all unique relations\n",
        "all_relations = set(triples_df_train[\"relation\"])\n",
        "\n",
        "# Create mapping dictionaries\n",
        "entity2id = {entity: idx for idx, entity in enumerate(all_entities)}\n",
        "relation2id = {relation: idx for idx, relation in enumerate(all_relations)}\n",
        "\n",
        "def encode_triples(df):\n",
        "    df[\"head\"] = df[\"head\"].map(entity2id)\n",
        "    df[\"relation\"] = df[\"relation\"].map(relation2id)\n",
        "    df[\"tail\"] = df[\"tail\"].map(entity2id)\n",
        "    return df\n",
        "\n",
        "# Encode train, test, and validation sets\n",
        "triples_df_train = encode_triples(triples_df_train)\n",
        "triples_df_test = encode_triples(triples_df_test)\n",
        "triples_df_val = encode_triples(triples_df_val)\n"
      ],
      "metadata": {
        "id": "pHs0Bg06wJEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Convert to tensor format\n",
        "train_tensor = torch.tensor(triples_df_train.values, dtype=torch.long)\n",
        "test_tensor = torch.tensor(triples_df_test.values, dtype=torch.long)\n",
        "val_tensor = torch.tensor(triples_df_val.values, dtype=torch.long)"
      ],
      "metadata": {
        "id": "0OT9yU2Kwh7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check the shape of the tensors\n",
        "print(\"Train Tensor Shape:\", train_tensor.shape)\n",
        "print(\"Test Tensor Shape:\", test_tensor.shape)\n",
        "print(\"Validation Tensor Shape:\", val_tensor.shape)\n",
        "\n",
        "# Access the first 5 samples\n",
        "print(\"First 5 Training Samples:\\n\", train_tensor[:5])\n",
        "\n",
        "# Get specific columns\n",
        "heads = train_tensor[:, 0]  # Head entities\n",
        "relations = train_tensor[:, 1]  # Relations\n",
        "tails = train_tensor[:, 2]  # Tail entities\n",
        "\n",
        "print(\"First 5 Head Entities:\\n\", heads[:5])\n",
        "print(\"First 5 Relations:\\n\", relations[:5])\n",
        "print(\"First 5 Tail Entities:\\n\", tails[:5])\n",
        "\n",
        "# Perform simple operations\n",
        "sum_tensor = heads + tails  # Example tensor addition\n",
        "print(\"Sum of Head & Tail Entities:\\n\", sum_tensor[:5])\n",
        "\n",
        "# Get unique values\n",
        "unique_heads = torch.unique(heads)\n",
        "print(f\"Unique Head Entities Count: {unique_heads.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4eelogAxJIe",
        "outputId": "55f64804-fb53-4e26-9ca1-70e43dc90324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Tensor Shape: torch.Size([1242550, 3])\n",
            "Test Tensor Shape: torch.Size([5000, 3])\n",
            "Validation Tensor Shape: torch.Size([5000, 3])\n",
            "First 5 Training Samples:\n",
            " tensor([[158292,    282,  79197],\n",
            "        [193190,    490, 184642],\n",
            "        [243732,     56,  86323],\n",
            "        [248311,    134,  78130],\n",
            "        [ 34938,    253, 231834]])\n",
            "First 5 Head Entities:\n",
            " tensor([158292, 193190, 243732, 248311,  34938])\n",
            "First 5 Relations:\n",
            " tensor([282, 490,  56, 134, 253])\n",
            "First 5 Tail Entities:\n",
            " tensor([ 79197, 184642,  86323,  78130, 231834])\n",
            "Sum of Head & Tail Entities:\n",
            " tensor([237489, 377832, 330055, 326441, 266772])\n",
            "Unique Head Entities Count: 116721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cpu\")  # Force CPU mode for now\n",
        "\n",
        "print(\"Using Device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5kgl1K566zF",
        "outputId": "8b83bad6-f269-4880-aecf-fbe1603497c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple MLP model\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "# Three layer network\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Set dimensions\n",
        "input_dim = 3  # (head, relation, tail)\n",
        "hidden_dim = 16\n",
        "output_dim = 1  # Binary classification or regression\n",
        "\n",
        "# Initialize model\n",
        "model = SimpleMLP(input_dim, hidden_dim, output_dim).to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()  # Example: MSE loss for regression\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Dummy training loop\n",
        "for epoch in range(5):  # Short training example\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(train_tensor.float())  # Convert tensor to float for Linear layers\n",
        "    loss = criterion(outputs, torch.rand_like(outputs))  # Dummy target values\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDdRgsUR6tST",
        "outputId": "3f4fe4e9-44d1-4ea5-aea7-77152d45276e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1196703744.0\n",
            "Epoch 2, Loss: 737774528.0\n",
            "Epoch 3, Loss: 400586816.0\n",
            "Epoch 4, Loss: 173411088.0\n",
            "Epoch 5, Loss: 46432520.0\n"
          ]
        }
      ]
    }
  ]
}