{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgZjnU9D6fApgffpvlgg1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidelgas/DataSciencePortfolio/blob/main/Neural%20Network%20with%20Knowledge%20Graph/KG_DNN_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook I will be creating a small NN and a knowledge graph."
      ],
      "metadata": {
        "id": "m_PtksQiY6Vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access to Google Drive\n",
        "# This seems to propagate credentials better from its own cell\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "7MO2kbk7afp3",
        "outputId": "a0d5dbd7-b675-417b-a526-a051de64309e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6674ac85ed2a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workfow\n",
        "\n",
        "\n",
        "1.   Load dataset\n",
        "2.   Preprocess and Clean the Data\n",
        "3.   Convert Data into a Knowledge Graph Structure\n",
        "4.   Generate Knowledge Graph Embeddings\n",
        "5.   Build a Graph-Based Recommendation Model\n",
        "6.   Integrate Conversational AI (Natural Language Model)\n",
        "7.   Train & Optimize the Full System\n",
        "8.   Implement Real-Time Inference for Recommendations\n",
        "9.   Deploy as an Interactive API or Chatbot\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TZGx4I6FHCHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "OljZpwOhukMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "https://github.com/zuohuif/COOKIE?utm_source=chatgpt.com\n",
        "\n"
      ],
      "metadata": {
        "id": "3a1AJuaaaaep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "GRLnTAAAuxUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scoring Criteria for Selecting an Encoder\n",
        "\n",
        "\n",
        "| **Factor**                 | **Description** |\n",
        "|---------------------------|----------------|\n",
        "| **Computational Efficiency** | How fast is the encoding on CPU/GPU? |\n",
        "| **Memory Usage**          | How much memory does it require? |\n",
        "| **Scalability**           | Can it handle large datasets like OpenBG500? |\n",
        "| **Preserves Semantic Meaning** | Does the encoding capture relationships between entities? |\n",
        "| **Compatibility with PyTorch** | How well does it integrate into PyTorch models? |\n",
        "| **Ease of Implementation** | How difficult is it to set up? |\n",
        "\n",
        "Each encoding method gets a **score from 1 to 5** for each factor.\n",
        "\n",
        "---\n",
        "\n",
        "## Scoring Different Encoding Methods\n",
        "\n",
        "| Encoding Method  | Computational Efficiency | Memory Usage | Scalability | Semantic Meaning | PyTorch Compatibility | Ease of Implementation | **Total Score** |\n",
        "|-----------------|------------------------|--------------|-------------|------------------|----------------------|--------------------|--------------|\n",
        "| **Label Encoding** (Integer Mapping) | **5** (Very fast) | **5** (Very low) | **5** (Handles millions of nodes) | **1** (No meaning captured) | **5** (PyTorch works with integers easily) | **5** (Simple `map()`) | **26** |\n",
        "| **One-Hot Encoding** | **2** (Slow for large datasets) | **1** (Consumes huge memory) | **1** (Bad for large graphs) | **3** (Some structure captured) | **3** (Can be used, but not ideal) | **3** (Easy but inefficient) | **13** |\n",
        "| **BERT Embeddings** (Text-Based) | **2** (Slow on CPU) | **3** (Moderate) | **3** (Can use pre-trained models) | **5** (Captures meaning well) | **4** (PyTorch supports it, but needs preprocessing) | **2** (Requires NLP model) | **19** |\n",
        "| **Word2Vec/FastText** | **3** (Faster than BERT) | **3** (Moderate) | **4** (Good for large datasets) | **4** (Captures word meaning) | **4** (PyTorch supports it) | **3** (Requires preprocessing) | **21** |\n",
        "| **Knowledge Graph Embeddings (TransE, RotatE)** | **4** (Moderate) | **4** (Efficient for large graphs) | **5** (Scales well) | **5** (Captures graph meaning) | **5** (Designed for PyTorch models) | **3** (Requires model training) | **26** |\n",
        "\n"
      ],
      "metadata": {
        "id": "w1WMfj7DuMfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all unique entities (from both head and tail)\n",
        "all_entities = set(triples_df_train[\"head\"]).union(set(triples_df_train[\"tail\"]))\n",
        "\n",
        "# Get all unique relations\n",
        "all_relations = set(triples_df_train[\"relation\"])\n",
        "\n",
        "# Create mapping dictionaries\n",
        "entity2id = {entity: idx for idx, entity in enumerate(all_entities)}\n",
        "relation2id = {relation: idx for idx, relation in enumerate(all_relations)}\n",
        "\n",
        "def encode_triples(df):\n",
        "    df[\"head\"] = df[\"head\"].map(entity2id)\n",
        "    df[\"relation\"] = df[\"relation\"].map(relation2id)\n",
        "    df[\"tail\"] = df[\"tail\"].map(entity2id)\n",
        "    return df\n",
        "\n",
        "# Encode train, test, and validation sets\n",
        "triples_df_train = encode_triples(triples_df_train)\n",
        "triples_df_test = encode_triples(triples_df_test)\n",
        "triples_df_val = encode_triples(triples_df_val)\n"
      ],
      "metadata": {
        "id": "pHs0Bg06wJEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Convert to tensor format\n",
        "train_tensor = torch.tensor(triples_df_train.values, dtype=torch.long)\n",
        "test_tensor = torch.tensor(triples_df_test.values, dtype=torch.long)\n",
        "val_tensor = torch.tensor(triples_df_val.values, dtype=torch.long)"
      ],
      "metadata": {
        "id": "0OT9yU2Kwh7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check the shape of the tensors\n",
        "print(\"Train Tensor Shape:\", train_tensor.shape)\n",
        "print(\"Test Tensor Shape:\", test_tensor.shape)\n",
        "print(\"Validation Tensor Shape:\", val_tensor.shape)\n",
        "\n",
        "# Access the first 5 samples\n",
        "print(\"First 5 Training Samples:\\n\", train_tensor[:5])\n",
        "\n",
        "# Get specific columns\n",
        "heads = train_tensor[:, 0]  # Head entities\n",
        "relations = train_tensor[:, 1]  # Relations\n",
        "tails = train_tensor[:, 2]  # Tail entities\n",
        "\n",
        "print(\"First 5 Head Entities:\\n\", heads[:5])\n",
        "print(\"First 5 Relations:\\n\", relations[:5])\n",
        "print(\"First 5 Tail Entities:\\n\", tails[:5])\n",
        "\n",
        "# Perform simple operations\n",
        "sum_tensor = heads + tails  # Example tensor addition\n",
        "print(\"Sum of Head & Tail Entities:\\n\", sum_tensor[:5])\n",
        "\n",
        "# Get unique values\n",
        "unique_heads = torch.unique(heads)\n",
        "print(f\"Unique Head Entities Count: {unique_heads.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4eelogAxJIe",
        "outputId": "55f64804-fb53-4e26-9ca1-70e43dc90324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Tensor Shape: torch.Size([1242550, 3])\n",
            "Test Tensor Shape: torch.Size([5000, 3])\n",
            "Validation Tensor Shape: torch.Size([5000, 3])\n",
            "First 5 Training Samples:\n",
            " tensor([[158292,    282,  79197],\n",
            "        [193190,    490, 184642],\n",
            "        [243732,     56,  86323],\n",
            "        [248311,    134,  78130],\n",
            "        [ 34938,    253, 231834]])\n",
            "First 5 Head Entities:\n",
            " tensor([158292, 193190, 243732, 248311,  34938])\n",
            "First 5 Relations:\n",
            " tensor([282, 490,  56, 134, 253])\n",
            "First 5 Tail Entities:\n",
            " tensor([ 79197, 184642,  86323,  78130, 231834])\n",
            "Sum of Head & Tail Entities:\n",
            " tensor([237489, 377832, 330055, 326441, 266772])\n",
            "Unique Head Entities Count: 116721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cpu\")  # Force CPU mode for now\n",
        "\n",
        "print(\"Using Device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5kgl1K566zF",
        "outputId": "8b83bad6-f269-4880-aecf-fbe1603497c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple MLP model\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "# Three layer network\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Set dimensions\n",
        "input_dim = 3  # (head, relation, tail)\n",
        "hidden_dim = 16\n",
        "output_dim = 1  # Binary classification or regression\n",
        "\n",
        "# Initialize model\n",
        "model = SimpleMLP(input_dim, hidden_dim, output_dim).to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()  # Example: MSE loss for regression\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Dummy training loop\n",
        "for epoch in range(5):  # Short training example\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(train_tensor.float())  # Convert tensor to float for Linear layers\n",
        "    loss = criterion(outputs, torch.rand_like(outputs))  # Dummy target values\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDdRgsUR6tST",
        "outputId": "3f4fe4e9-44d1-4ea5-aea7-77152d45276e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1196703744.0\n",
            "Epoch 2, Loss: 737774528.0\n",
            "Epoch 3, Loss: 400586816.0\n",
            "Epoch 4, Loss: 173411088.0\n",
            "Epoch 5, Loss: 46432520.0\n"
          ]
        }
      ]
    }
  ]
}