{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49baada7-a8a7-4254-b2d7-d5c36a6f1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"LLM RAG Frontend.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1rdGpMEfO2-LX7S3gp5DI1HsLDpySkAIC\n",
    "\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# Set page configuration - MUST BE FIRST STREAMLIT COMMAND\n",
    "st.set_page_config(\n",
    "    page_title=\"BMW E9 Knowledge Base\",\n",
    "    page_icon=\"ðŸš—\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Then import other libraries\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Debug information can go here, after st.set_page_config\n",
    "st.write(\"Version: 2.0 - Using environment variables\")\n",
    "\n",
    "# Get credentials from environment variables\n",
    "sf_user = os.environ.get('SNOWFLAKE_USER')\n",
    "sf_pass = os.environ.get('SNOWFLAKE_PASSWORD')\n",
    "sf_acct = os.environ.get('SNOWFLAKE_ACCOUNT')\n",
    "openai_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# ======== SIDEBAR: Configuration ========\n",
    "with st.sidebar:\n",
    "    st.title(\"BMW E9 Knowledge Base\")\n",
    "    st.image(\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/BMW_E9_front_20071007.jpg/1280px-BMW_E9_front_20071007.jpg\", width=300)\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # Configuration options\n",
    "    st.subheader(\"Configuration\")\n",
    "\n",
    "    # Model selection\n",
    "    embedding_model = st.selectbox(\n",
    "        \"Embedding Model\",\n",
    "        [\"all-MiniLM-L6-v2\", \"all-mpnet-base-v2\"],\n",
    "        index=0\n",
    "    )\n",
    "\n",
    "    llm_model = st.selectbox(\n",
    "        \"Language Model\",\n",
    "        [\"gpt-3.5-turbo\", \"gpt-4\"],\n",
    "        index=0\n",
    "    )\n",
    "\n",
    "    # Search parameters\n",
    "    top_k = st.slider(\"Number of documents to retrieve\", 1, 10, 5)\n",
    "    temperature = st.slider(\"Temperature\", 0.0, 1.0, 0.2, 0.1)\n",
    "\n",
    "    # Add a citation toggle\n",
    "    show_citations = st.toggle(\"Show Citations\", value=True)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.caption(\"Created by David Elgas\")\n",
    "\n",
    "# ======== FUNCTIONS ========\n",
    "@st.cache_resource\n",
    "def load_data_from_snowflake():\n",
    "    \"\"\"Load data from Snowflake database\"\"\"\n",
    "    # Connect to Snowflake using environment variables\n",
    "    conn = snowflake.connector.connect(\n",
    "        user=sf_user,\n",
    "        password=sf_pass,\n",
    "        account=sf_acct,\n",
    "        database='E9_CORPUS',\n",
    "        schema='E9_CORPUS_SCHEMA',\n",
    "        warehouse='COMPUTE_WH'\n",
    "    )\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT THREAD_ID, THREAD_TITLE, THREAD_FIRST_POST, THREAD_ALL_POSTS FROM E9_CORPUS.E9_CORPUS_SCHEMA.E9_FORUM_CORPUS\")\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(rows, columns=['thread_id', 'thread_title', 'thread_first_post', 'thread_all_posts'])\n",
    "\n",
    "    # Create a combined text field\n",
    "    df[\"full_text\"] = (\n",
    "        df[\"thread_title\"].fillna(\"\") + \"\\n\\n\" +\n",
    "        df[\"thread_first_post\"].fillna(\"\") + \"\\n\\n\" +\n",
    "        df[\"thread_all_posts\"].fillna(\"\")\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "@st.cache_resource\n",
    "def load_embedding_model(model_name):\n",
    "    \"\"\"Load the embedding model\"\"\"\n",
    "    return SentenceTransformer(model_name)\n",
    "\n",
    "@st.cache_resource\n",
    "def create_faiss_index(df, model):\n",
    "    \"\"\"Create FAISS index from corpus embeddings\"\"\"\n",
    "    corpus_embeddings = model.encode(df[\"full_text\"].tolist(), show_progress_bar=True)\n",
    "\n",
    "    dimension = corpus_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(corpus_embeddings)\n",
    "\n",
    "    return index, corpus_embeddings\n",
    "\n",
    "def search_similar_documents(question, index, model, df, top_k=5):\n",
    "    \"\"\"Search for similar documents using the FAISS index\"\"\"\n",
    "    question_embedding = model.encode([question])\n",
    "    distances, indices = index.search(question_embedding, top_k)\n",
    "\n",
    "    results = []\n",
    "    for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):\n",
    "        results.append({\n",
    "            'index': idx,\n",
    "            'distance': float(dist),\n",
    "            'thread_id': int(df.iloc[idx][\"thread_id\"]),\n",
    "            'title': df.iloc[idx][\"thread_title\"],\n",
    "            'first_post': df.iloc[idx][\"thread_first_post\"],\n",
    "            'full_text': df.iloc[idx][\"full_text\"]\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "def generate_answer(question, retrieved_docs, with_context=True):\n",
    "    \"\"\"Generate answer using OpenAI API\"\"\"\n",
    "    client = OpenAI(api_key=openai_key)\n",
    "\n",
    "    if with_context:\n",
    "        context = \"\\n\\n\".join([f\"Thread {i+1}:\\n{doc['full_text']}\" for i, doc in enumerate(retrieved_docs)])\n",
    "        prompt = f\"\"\"You are an expert on BMW E9 maintenance. Use the following forum threads to answer the question.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"You are an expert on BMW E9 maintenance.\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# ======== MAIN APP ========\n",
    "# Load data and models\n",
    "try:\n",
    "    with st.spinner(\"Loading data and models...\"):\n",
    "        df = load_data_from_snowflake()\n",
    "        model = load_embedding_model(embedding_model)\n",
    "        index, embeddings = create_faiss_index(df, model)\n",
    "        st.success(f\"Loaded {len(df)} forum threads\")\n",
    "except Exception as e:\n",
    "    st.error(f\"Error loading data: {str(e)}\")\n",
    "    st.stop()\n",
    "\n",
    "# App title and description\n",
    "st.title(\"BMW E9 Knowledge Base\")\n",
    "st.markdown(\"\"\"\n",
    "This application provides answers to your BMW E9 maintenance and repair questions using data from an E9 forum.\n",
    "The system uses RAG (Retrieval-Augmented Generation) to find relevant forum posts and generate accurate answers.\n",
    "\"\"\")\n",
    "\n",
    "# User input\n",
    "question = st.text_input(\"Ask a question about BMW E9 maintenance:\", \"How do I remove the steering wheel in an E9?\")\n",
    "\n",
    "if st.button(\"Ask Question\", type=\"primary\"):\n",
    "    if not question:\n",
    "        st.warning(\"Please enter a question\")\n",
    "    else:\n",
    "        # Search for relevant documents\n",
    "        with st.spinner(\"Searching for relevant information...\"):\n",
    "            results = search_similar_documents(question, index, model, df, top_k)\n",
    "\n",
    "        # Generate answer with context\n",
    "        with st.spinner(\"Generating answer...\"):\n",
    "            answer = generate_answer(question, results)\n",
    "\n",
    "        # Display answer\n",
    "        st.markdown(\"### Answer\")\n",
    "        st.markdown(answer)\n",
    "\n",
    "        # Display source documents\n",
    "        if show_citations:\n",
    "            st.markdown(\"### Sources\")\n",
    "            for i, result in enumerate(results):\n",
    "                with st.expander(f\"Thread {i+1}: {result['title']} (Distance: {result['distance']:.4f})\"):\n",
    "                    st.markdown(f\"**Thread ID:** {result['thread_id']}\")\n",
    "                    st.markdown(f\"**First Post:**\\n{result['first_post'][:500]}...\")\n",
    "\n",
    "# Add information about the database\n",
    "st.markdown(\"---\")\n",
    "with st.expander(\"About the Database\"):\n",
    "    st.markdown(f\"\"\"\n",
    "    - **Total Threads:** {len(df)}\n",
    "    - **Embedding Model:** {embedding_model}\n",
    "    - **Language Model:** {llm_model}\n",
    "    - **Index Type:** FAISS (Facebook AI Similarity Search)\n",
    "    \"\"\")\n",
    "\n",
    "    # Display statistics\n",
    "    if st.checkbox(\"Show Database Statistics\"):\n",
    "        # Calculate statistics\n",
    "        avg_title_len = df['thread_title'].str.len().mean()\n",
    "        avg_posts_len = df['thread_all_posts'].str.len().mean()\n",
    "\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            st.metric(\"Avg. Title Length\", f\"{avg_title_len:.1f} chars\")\n",
    "        with col2:\n",
    "            st.metric(\"Avg. Post Length\", f\"{avg_posts_len:.1f} chars\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
